{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wBrlqHJdBH7",
        "outputId": "4e8882ed-4e6c-4565-c72e-3f33667d54e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/gdrive/MyDrive/utils/coco-caption-master /content/"
      ],
      "metadata": {
        "id": "yz6BRxeIg_Tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gdrive/MyDrive/utils/change_captions.json /content/"
      ],
      "metadata": {
        "id": "RumY0MwzhGz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gdrive/MyDrive/utils/no_change_captions.json /content/"
      ],
      "metadata": {
        "id": "mC4LTWKYhL87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gdrive/MyDrive/utils/eval_utils.py /content/"
      ],
      "metadata": {
        "id": "B2BcFJhEhSVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/coco-caption-master/pycocoevalcap /content/"
      ],
      "metadata": {
        "id": "iJmvKhn6zheM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/coco-caption-master/pycocotools /content/"
      ],
      "metadata": {
        "id": "CL_31z2M0GeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gdrive/MyDrive/utils/type_mapping.json /content/"
      ],
      "metadata": {
        "id": "KiOahOFc-RbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q136SsKU28GE",
        "outputId": "f63234df-6464-40c3-e7c8-7fb6aec263b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_utils.py"
      ],
      "metadata": {
        "id": "Tx3Udx1ChlLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gdrive/MyDrive/utils/total_change_captions_reformat.json /content/"
      ],
      "metadata": {
        "id": "FJZsdGkzvmJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/gdrive/MyDrive/utils/evaluate.py /content/"
      ],
      "metadata": {
        "id": "y_gziI898oz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/gdrive/MyDrive/utils/captions /content/"
      ],
      "metadata": {
        "id": "TxQy40l88rak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jNLOPmG9UB7",
        "outputId": "5f8f41b2-27a3-436a-f662-dfaf942d11f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py --results_dir /content/captions --anno /content/total_change_captions_reformat.json --type_file /content/type_mapping.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9xhCtH08wgR",
        "outputId": "a7cbf03b-8cbb-4384-d830-95c0170519a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/captions/test/sc_results.json\n",
            "loading annotations into memory...\n",
            "0:00:00.649169\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 347505 tokens at 511419.91 tokens per second.\n",
            "PTBTokenizer tokenized 63276 tokens at 163935.88 tokens per second.\n",
            "setting up scorers...\n",
            "computing Bleu score...\n",
            "{'testlen': 59292, 'reflen': 57287, 'guess': [59292, 55307, 51322, 47337], 'correct': [47970, 34705, 23224, 14059]}\n",
            "ratio: 1.0349992144814524\n",
            "Bleu_1: 0.809\n",
            "Bleu_2: 0.713\n",
            "Bleu_3: 0.612\n",
            "Bleu_4: 0.511\n",
            "computing METEOR score...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluate.py\", line 34, in <module>\n",
            "    sc_eval_result = score_generation(args.anno, sc_path)\n",
            "  File \"/content/eval_utils.py\", line 102, in score_generation\n",
            "    coco_eval.evaluate()\n",
            "  File \"/content/cococaption/pycocoevalcap/eval.py\", line 52, in evaluate\n",
            "    score, scores = scorer.compute_score(gts, res)\n",
            "  File \"/content/cococaption/pycocoevalcap/meteor/meteor.py\", line 37, in compute_score\n",
            "    stat = self._stat(res[i][0], gts[i])\n",
            "  File \"/content/cococaption/pycocoevalcap/meteor/meteor.py\", line 56, in _stat\n",
            "    return self.meteor_p.stdout.readline().strip()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py --results_dir /content/captions --anno /content/total_change_captions_reformat.json --type_file /content/type_mapping.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cAlbx0gyPvN",
        "outputId": "7eac55a4-e1ac-4e66-9010-f4b74b634e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "0:00:01.633022\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "DONE (t=0.05s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 347505 tokens at 413975.97 tokens per second.\n",
            "PTBTokenizer tokenized 63276 tokens at 165645.05 tokens per second.\n",
            "setting up scorers...\n",
            "computing Bleu score...\n",
            "{'testlen': 59292, 'reflen': 57287, 'guess': [59292, 55307, 51322, 47337], 'correct': [47970, 34705, 23224, 14059]}\n",
            "ratio: 1.0349992144814524\n",
            "Bleu_1: 0.809\n",
            "Bleu_2: 0.713\n",
            "Bleu_3: 0.612\n",
            "Bleu_4: 0.511\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.654\n",
            "computing CIDEr score...\n",
            "CIDEr: 1.007\n",
            "computing SPICE score...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/evaluate.py\", line 33, in <module>\n",
            "    sc_eval_result = score_generation(args.anno, sc_path)\n",
            "  File \"/content/eval_utils.py\", line 102, in score_generation\n",
            "    coco_eval.evaluate()\n",
            "  File \"/content/cococaption/pycocoevalcap/eval.py\", line 55, in evaluate\n",
            "    score, scores = scorer.compute_score(gts, res)\n",
            "  File \"/content/cococaption/pycocoevalcap/spice/spice.py\", line 54, in compute_score\n",
            "    json.dump(input_data, in_file, indent=2)\n",
            "  File \"/usr/lib/python3.9/json/__init__.py\", line 180, in dump\n",
            "    fp.write(chunk)\n",
            "  File \"/usr/lib/python3.9/tempfile.py\", line 617, in func_wrapper\n",
            "    return func(*args, **kwargs)\n",
            "TypeError: a bytes-like object is required, not 'str'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxd9fh1f4Mja"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}